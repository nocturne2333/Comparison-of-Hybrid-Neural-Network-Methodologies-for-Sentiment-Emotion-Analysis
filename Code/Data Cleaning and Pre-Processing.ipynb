{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Packages\n",
    "import os\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['August', 'Final', 'twitter_stream_2019_08_01.tar', 'twitter_stream_2019_08_02.tar', 'twitter_stream_2019_08_03.tar', 'twitter_stream_2019_08_04.tar', 'twitter_stream_2019_08_05.tar', 'twitter_stream_2019_08_06.tar', 'twitter_stream_2019_08_07.tar', 'twitter_stream_2019_08_08.tar', 'twitter_stream_2019_08_09.tar', 'twitter_stream_2019_08_10.tar', 'twitter_stream_2019_08_11.tar', 'twitter_stream_2019_08_12.tar', 'twitter_stream_2019_08_13.tar', 'twitter_stream_2019_08_14.tar', 'twitter_stream_2019_08_15.tar', 'twitter_stream_2019_08_16.tar', 'twitter_stream_2019_08_17.tar', 'twitter_stream_2019_08_18.tar', 'twitter_stream_2019_08_19.tar', 'twitter_stream_2019_08_20.tar', 'twitter_stream_2019_08_21.tar', 'twitter_stream_2019_08_22.tar', 'twitter_stream_2019_08_23.tar', 'twitter_stream_2019_08_24.tar', 'twitter_stream_2019_08_25.tar', 'twitter_stream_2019_08_26.tar', 'twitter_stream_2019_08_27.tar', 'twitter_stream_2019_08_28.tar', 'twitter_stream_2019_08_29.tar', 'twitter_stream_2019_08_30.tar', 'twitter_stream_2019_08_31.tar']\n"
     ]
    }
   ],
   "source": [
    "# Base Folder of all Twitter tar files\n",
    "twitter_folder = 'E:/Study Material/Data Mining and Machine Learning - 2/Project/Data'\n",
    "twitter_data = os.listdir(twitter_folder)\n",
    "print(twitter_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction of tarfiles\n",
    "for i in range(0, len(twitter_data)):\n",
    "    if tarfile.is_tarfile(twitter_folder+\"/\"+twitter_data[i]):\n",
    "        tf = tarfile.open(twitter_folder+\"/\"+twitter_data[i])\n",
    "        tf.extractall(path = twitter_folder+\"/August\")\n",
    "        tf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1411"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the environment path for all json.bz2 files\n",
    "days = os.listdir(twitter_folder+\"/August/\")\n",
    "abspathev = []\n",
    "for i in range(0,1):\n",
    "    hour = os.listdir(twitter_folder+\"/August/\"+days[i])\n",
    "    for j in range(0,len(hour)):\n",
    "        minute = os.listdir(twitter_folder+\"/August/\"+days[i]+\"/\"+hour[j])\n",
    "        for k in range(0,len(minute)):\n",
    "            abspathev.append(os.path.abspath(twitter_folder+\"/August/\"+days[i]+\"/\"+hour[j]+\"/\"+minute[k]))\n",
    "len(abspathev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enabling Spark Context and creating Spark Session\n",
    "#sc = SparkContext()\n",
    "spark = SparkSession.Builder().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading all json.bz2 files and creating a spark dataframe\n",
    "df = spark.read.json(abspathev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a sql view\n",
    "df.createOrReplaceTempView(\"tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting only required data from the spark dataframe\n",
    "sqlDF = spark.sql(\"SELECT created_at, array_join(entities.hashtags.text, ',') as hashtags, id as tweetid, lang, text as tweet, user.id as userid FROM tweet where lang like ('%en%') and text not like ('%RT%')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41292\n"
     ]
    }
   ],
   "source": [
    "# Filtering Tweets that have non-empty hashtags (August - 33001619)\n",
    "sqlDF = sqlDF.filter(\"hashtags != ''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing data to csv file\n",
    "twitter_df = sqlDF.toPandas()\n",
    "twitter_df.to_csv(r'E:\\Study Material\\Data Mining and Machine Learning - 2\\Project\\Data\\Final\\August01_Tweets_Final.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
